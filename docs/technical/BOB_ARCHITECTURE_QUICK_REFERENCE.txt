================================================================================
BOB GOOGLE MAPS V3.0 - ARCHITECTURAL ANALYSIS SUMMARY
================================================================================

QUESTION 1: OVERALL ARCHITECTURE PATTERN
────────────────────────────────────────
Type: Hybrid Multi-Engine with Intelligent Fallback

Flow: Cache → Playwright (async) → Selenium (sync) → Failure

Key Patterns:
  • Strategy Pattern: Multiple extraction engines with dynamic selection
  • Fallback Chain: Graceful degradation through multiple layers
  • Async-First with Sync Fallback: Playwright async, with thread pool wrapper
  • Repository Pattern: CacheManager for persistence
  • Decorator Pattern: Optimized variants wrap base implementations


QUESTION 2: MAIN DEPENDENCIES & VERSIONS
─────────────────────────────────────────
Core Web Automation:
  • Selenium >= 4.15.0       (WebDriver browser automation)
  • Playwright >= 1.40.0     (Modern async automation)
  • undetected-chromedriver >= 3.5.0  (Anti-bot bypass)

Network:
  • requests >= 2.31.0       (HTTP client)
  • urllib3 >= 2.0.0         (HTTP utilities)

Async Support:
  • greenlet >= 3.0.0        (Lightweight concurrency)

Python: 3.8+ (recommended 3.10+)


QUESTION 3: HYBRID EXTRACTION ENGINE MECHANICS
───────────────────────────────────────────────
Step 1: Cache Check (0.1s if hit, skips rest)
  └─ 24-hour expiration, multi-identifier lookup

Step 2: Playwright Extraction (11-30s)
  • Async/await architecture
  • Network API interception for raw JSON
  • Resource blocking (images/CSS/fonts) - 66% memory reduction
  • Auto-waiting built-in
  • Parallel via asyncio.gather() with semaphore
  • Event loop conflict handling: ThreadPoolExecutor wrapper

Step 3: Selenium V2 Fallback (20-40s)
  • Undetected-chromedriver (stealth mode)
  • 6-layer multi-strategy element finder
  • Selector caching for performance
  • Auto-healing selectors
  • Human-like interactions via ActionChains

Success Rate: 95%+ achieved through fallback chain


QUESTION 4: CACHING STRATEGY & LIMITATIONS
───────────────────────────────────────────
Technology: SQLite (bob_cache_ultimate.db)

Schema:
  • BUSINESSES (main, indexed on place_id, cid, name)
  • REVIEWS (child, linked via place_id)
  • IMAGES (child, linked via place_id)
  • EXTRACTION_HISTORY (analytics)

Performance:
  • Cache hit: 0.1s (500x faster than fresh)
  • Cache lookup: <1ms (indexed)
  • Cache hit rate: 70-80% in typical usage

Features:
  • 24-hour default expiration
  • Incremental updates only
  • Multi-identifier lookup (place_id, cid, name)
  • Auto-cleanup (configurable days)

Limitations:
  1. Schema migration drops all tables (design issue, auto-detected and fixed)
  2. Disk I/O overhead on every write (mitigated by batching)
  3. SQLite write-lock limitations (mitigated by subprocess isolation)
  4. Alternative: HybridExtractorOptimized (cache-free variant)


QUESTION 5: BATCH PROCESSING
─────────────────────────────
Technology: Subprocess Isolation

Architecture:
  Each business extraction runs in isolated Python process
  └─ Guarantees: Complete memory cleanup, no zombie processes

Flow:
  1. Generate Python code string with extraction logic
  2. subprocess.run() with 120s timeout
  3. Parse result between BOB_RESULT_START/END markers
  4. JSON encode/decode for universal format
  5. Process terminates, OS reclaims all memory

Features:
  • 100% reliability (errors don't affect others)
  • Sequential processing (configurable rate limiting)
  • Retry logic with automatic failure detection
  • Results in list format (success/failure tracking)

Performance:
  • Subprocess overhead: ~200ms per business
  • Timeout: 120s (configurable)
  • Memory per subprocess: <60MB (auto-cleaned)
  • Success rate: 100% (3/3 tested on real data)
  • Speed: 21.2s per business (with 20s rate limiting)


QUESTION 6: ERROR HANDLING PATTERNS
────────────────────────────────────
Hierarchical Multi-Level Error Handling:

Level 1: Engine Selection (HybridExtractor)
  • Cache lookup errors (silent, no cache = continue)
  • Playwright async errors → fallback to Selenium
  • Selenium WebDriver errors → return failure

Level 2: Extraction Engine
  • Navigation timeouts (PlaywrightTimeout)
  • Element selection failures (auto-healing retry)
  • Data parsing errors (graceful degradation)

Level 3: Data Retrieval (API/Network)
  • Response parsing failures
  • JSON deserialization errors
  • Network timeouts

Level 4: Subprocess (Batch Processing)
  • Timeout expired → error result
  • Process creation failure → error result
  • Output parsing failure → error result

Strategies:
  • Fallback chain: Try → Fallback → Try → Return failure
  • Selector auto-healing: 6-strategy element finding
  • Timeout management: Different limits for different ops
  • Process isolation: Errors don't cascade
  • Graceful degradation: Cache miss = fresh extraction


QUESTION 7: INTEGRATION WITH OTHER BOB PRODUCTS
────────────────────────────────────────────────
Current Status: Reference architecture exists, not fully implemented

Data Flow (Planned):
  BOB-Google-Maps → BOB-Central-Integration → BOB-Email-Discovery → BOB-Zepto-Mail
  108-field data → Unified Intelligence → Enriched Data → Campaigns

Exports:
  • JSON (API-ready)
  • CSV (spreadsheet-compatible)
  • Database (SQL INSERT)
  • CRM formats (HubSpot, Salesforce)

Integration Hub (reference code):
  from bob_integration_hub import BOBIntegrationHub
  hub.register_product("bob_google_maps", {...})
  hub.sync_data_from_product("bob_google_maps")
  
Status: Integration infrastructure designed but imports not in production codebase


QUESTION 8: MAIN CONFIGURATION OPTIONS
───────────────────────────────────────
Three Configuration Systems:

1. ExtractorConfig (dataclass):
   • headless, timeout, page_load_timeout
   • max_retries, retry_delay
   • stealth_mode, user_agent
   • intercept_network, block_resources
   • max_reviews, max_images
   • include_reviews, include_images
   • cache_dir, logs_dir, data_dir
   • min_quality_score

2. CacheConfig:
   • enabled, cache_db_path
   • expiration_hours (default 24)
   • auto_cleanup, cleanup_days
   • max_cache_size_mb

3. ParallelConfig:
   • enabled, max_concurrent (default 10)
   • context_pool_size, max_memory_mb
   • max_cpu_percent, batch_size
   • checkpoint_interval

Configuration Sources (priority):
  1. Code: ExtractorConfig(headless=True, ...)
  2. Environment: os.getenv('BOB_HEADLESS')
  3. YAML: config.yaml file
  4. Defaults: Built-in dataclass defaults

Environment Variables:
  • BOB_HEADLESS=true
  • BOB_TIMEOUT=60
  • BOB_STEALTH=true
  • BOB_CACHE_ENABLED=true
  • BOB_CACHE_PATH="./bob_cache_ultimate.db"
  • BOB_MEMORY_OPTIMIZED=true
  • BOB_MAX_CONCURRENT=10


QUESTION 9: ASYNC/AWAIT PATTERNS
─────────────────────────────────
Async Architecture:

Playwright (100% async):
  async def extract_business(self, url):
    async with async_playwright() as p:
      browser = await p.chromium.launch()
      await browser.close()

Parallel Extraction (asyncio.gather + Semaphore):
  async def extract_multiple_parallel(self, urls):
    semaphore = asyncio.Semaphore(max_concurrent)
    results = await asyncio.gather(*[extract_with_semaphore(url) for url in urls])

Network Interception (async):
  async def capture_response(self, response):
    data = await response.json()

Event Loop Conflict Handling:
  try:
    loop = asyncio.get_running_loop()
    # Use ThreadPoolExecutor to wrap asyncio.run()
  except RuntimeError:
    # No loop, safe to use asyncio.run()

Selenium (sync, no await):
  • No async equivalent
  • Blocking I/O (WebDriver calls)
  • Used as fallback only

Performance:
  • Single Playwright extraction: 11s (2.7x faster than Selenium)
  • 10 parallel extractions: 15s (20x faster than sequential)
  • Event loop overhead minimal with proper handling


QUESTION 10: MEMORY MANAGEMENT
───────────────────────────────
Memory Architecture:

Lifecycle:
  Start: ~50MB (Python runtime)
  ↓
  Browser launch: ~85MB peak (Chromium)
  ↓
  Page loading: ~35MB (data buffering)
  ↓
  Extraction: ~15MB (parse & store)
  ↓
  Cleanup: ~50MB (browser closes)
  ↓
  Garbage collection: gc.collect() forced

Optimization Techniques:

1. Resource Blocking (Playwright):
   • Block images (30-50MB saved)
   • Block CSS/fonts (5-10MB saved)
   • Block media (5MB saved)
   Total: 66% memory reduction

2. Garbage Collection (psutil monitoring):
   • gc.collect() after each extraction
   • Memory reduction: ~35MB per cycle
   • Explicit cleanup vs reliance on GC

3. Browser Context Cleanup:
   • Guaranteed cleanup with try-finally
   • Immediate resource release
   • No lingering processes

4. Subprocess Isolation (BatchProcessor):
   • Each process <60MB
   • OS reclaims 100% on process exit
   • No memory leakage across extractions

5. Memory Optimization Variant (HybridExtractorOptimized):
   • Cache-free extraction
   • Direct memory tracking with psutil
   • Forced GC between operations
   • Peak memory: <50MB

Benchmarks vs Traditional Scrapers:
  
  Metric                Traditional    BOB Optimized    Improvement
  ──────────────────    ────────────   ─────────────    ─────────────
  Base Memory           50MB           50MB             Same
  Peak Memory           250MB          85MB             66% reduction
  Memory Increase       200MB          35MB             82.5% reduction
  Process Leakage       Present        None             100% eliminated
  Cleanup Time          8+ seconds     <1 second        8x faster

Memory Configuration:
  • ParallelConfig.max_memory_mb (default 2048)
  • BOB_MEMORY_OPTIMIZED=true environment variable
  • Docker container limits: docker run -m 2g


================================================================================
ARCHITECTURE SUMMARY TABLE
================================================================================

Aspect               Technology           Details
──────────────────   ──────────────────   ─────────────────────────────────
Architecture         Hybrid Multi-Engine  Cache→Playwright→Selenium fallback
Speed                3-5x faster          11-30s vs 30-50s traditional
Success Rate         95%+ production       Triple-engine redundancy
Memory Footprint     <50MB optimized       66% reduction vs competitors
Caching              SQLite (24h default)  0.1s hits, 500x faster
Batch Processing     Subprocess isolated   100% reliability, <60MB per proc
Error Handling       Hierarchical          4-level fallback chain
Configuration        Flexible multi-layer  Code, env, YAML, defaults
Async/Await          Playwright native     asyncio.gather + semaphore
Memory Management    GC + blocking         psutil monitoring, cleanup

================================================================================
