#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
é‡è¯•å¤±è´¥æŠ“å–è„šæœ¬
=================

ä¸“é—¨ç”¨äºé‡æ–°æŠ“å–ä¹‹å‰å¤±è´¥çš„è®°å½•çš„è„šæœ¬ã€‚

åŠŸèƒ½ç‰¹æ€§ï¼š
- è‡ªåŠ¨æ‰«æbatch_outputç›®å½•ä¸­æ‰€æœ‰å¤±è´¥çš„JSONæ–‡ä»¶
- æå–å¤±è´¥è®°å½•çš„ä¿¡æ¯å¹¶é‡æ–°ç»„ç»‡ä¸ºè¾“å…¥æ ¼å¼
- æ”¯æŒæŒ‰é”™è¯¯ä»£ç ç­›é€‰é‡è¯•ï¼ˆå¦‚åªé‡è¯•è¶…æ—¶é”™è¯¯ï¼‰
- æ”¯æŒé™åˆ¶é‡è¯•æ•°é‡
- è¯¦ç»†çš„è¿›åº¦æŠ¥å‘Šå’Œç»Ÿè®¡ä¿¡æ¯
- å¯é€‰æ‹©æ€§åœ°æ›´æ–°é‡è¯•æ¬¡æ•°

ä½¿ç”¨æ–¹æ³•ï¼š
1. é‡è¯•æ‰€æœ‰å¤±è´¥è®°å½•ï¼š
   python retry_failed_scrapes.py

2. åªé‡è¯•è¶…æ—¶é”™è¯¯ï¼ˆé”™è¯¯ä»£ç 1002ï¼‰ï¼š
   python retry_failed_scrapes.py --error-codes 1002

3. é™åˆ¶é‡è¯•æ•°é‡ï¼ˆæµ‹è¯•ï¼‰ï¼š
   python retry_failed_scrapes.py --max-retry 10

4. è¯¦ç»†æ¨¡å¼ï¼š
   python retry_failed_scrapes.py --verbose
"""

import json
import os
import sys
import argparse
import logging
import shutil
from pathlib import Path
from typing import Dict, List, Any, Set, Optional
from datetime import datetime
import subprocess
from concurrent.futures import ThreadPoolExecutor, as_completed
import threading
from tqdm import tqdm

# å¼•å…¥ç°æœ‰çš„æ‰¹é‡å¤„ç†å™¨
try:
    from batch_scraper import BatchGoogleMapsScraper, DEFAULT_CONFIG, TEST_CONFIG
except ImportError:
    print("é”™è¯¯ï¼šæ— æ³•å¯¼å…¥batch_scraperæ¨¡å—ã€‚è¯·ç¡®ä¿batch_scraper.pyåœ¨åŒä¸€ç›®å½•ä¸‹ã€‚")
    sys.exit(1)

class FailedScrapeRetryProcessor:
    """å¤±è´¥æŠ“å–é‡è¯•å¤„ç†å™¨"""
    
    def __init__(self, output_dir: str = "batch_output", config: Optional[Dict] = None):
        """
        åˆå§‹åŒ–é‡è¯•å¤„ç†å™¨
        
        Args:
            output_dir: è¾“å‡ºç›®å½•è·¯å¾„
            config: é…ç½®å‚æ•°å­—å…¸
        """
        self.output_dir = Path(output_dir)
        self.config = config or DEFAULT_CONFIG.copy()
        
        # è®¾ç½®æ—¥å¿—
        self.setup_logging()
        
        # åˆ›å»ºæ‰¹é‡å¤„ç†å™¨å®ä¾‹
        self.batch_processor = BatchGoogleMapsScraper(
            output_base_dir=str(self.output_dir),
            config=self.config
        )
        
        self.logger.info(f"å¤±è´¥æŠ“å–é‡è¯•å¤„ç†å™¨å·²åˆå§‹åŒ–")
        self.logger.info(f"è¾“å‡ºç›®å½•: {self.output_dir}")
        
    def setup_logging(self):
        """è®¾ç½®æ—¥å¿—ç³»ç»Ÿ"""
        logging.basicConfig(
            level=logging.INFO,
            format='%(asctime)s - %(levelname)s - %(message)s',
            handlers=[
                logging.StreamHandler(sys.stdout)
            ]
        )
        self.logger = logging.getLogger(__name__)
        
    def scan_failed_files(self) -> List[Dict[str, Any]]:
        """
        æ‰«ææ‰€æœ‰å¤±è´¥çš„JSONæ–‡ä»¶
        
        Returns:
            å¤±è´¥è®°å½•åˆ—è¡¨
        """
        failed_records = []
        
        if not self.output_dir.exists():
            self.logger.warning(f"è¾“å‡ºç›®å½•ä¸å­˜åœ¨: {self.output_dir}")
            return failed_records
        
        self.logger.info("å¼€å§‹æ‰«æå¤±è´¥çš„æŠ“å–è®°å½•...")
        
        # é€’å½’æ‰«ææ‰€æœ‰JSONæ–‡ä»¶
        json_files = list(self.output_dir.rglob("*.json"))
        
        # æ’é™¤progress.jsonç­‰ç³»ç»Ÿæ–‡ä»¶
        json_files = [f for f in json_files if f.name not in ['progress.json']]
        
        self.logger.info(f"æ‰¾åˆ° {len(json_files)} ä¸ªJSONæ–‡ä»¶ï¼Œæ­£åœ¨æ£€æŸ¥å¤±è´¥è®°å½•...")
        
        failed_count = 0
        for json_file in tqdm(json_files, desc="æ‰«ææ–‡ä»¶"):
            try:
                with open(json_file, 'r', encoding='utf-8') as f:
                    data = json.load(f)
                
                # æ£€æŸ¥æ˜¯å¦ä¸ºå¤±è´¥è®°å½•
                if not data.get('scrape_success', True):  # scrape_successä¸ºFalseæˆ–ä¸å­˜åœ¨
                    # æå–è·¯å¾„ä¿¡æ¯æ¥ç¡®å®šparent_typeå’Œsub_type
                    relative_path = json_file.relative_to(self.output_dir)
                    path_parts = relative_path.parts
                    
                    if len(path_parts) >= 2:
                        parent_type = path_parts[0]
                        sub_type = path_parts[1]
                        
                        failed_record = {
                            'place_id': data.get('place_id'),
                            'Maps_url': data.get('Maps_url'),
                            'parent_type': parent_type,
                            'sub_type': sub_type,
                            'grid_id': data.get('grid_id', ''),
                            'error_code': data.get('scrape_error_code'),
                            'error_message': data.get('scrape_error_message', ''),
                            'retry_attempt': data.get('retry_attempt', 0),
                            'scraped_at': data.get('scraped_at'),
                            'file_path': str(json_file)
                        }
                        
                        # ç¡®ä¿å¿…è¦å­—æ®µå­˜åœ¨
                        if failed_record['place_id'] and failed_record['Maps_url']:
                            failed_records.append(failed_record)
                            failed_count += 1
                        else:
                            self.logger.warning(f"è·³è¿‡æ ¼å¼ä¸å®Œæ•´çš„å¤±è´¥è®°å½•: {json_file}")
                    else:
                        self.logger.warning(f"æ— æ³•ç¡®å®šç±»å‹çš„æ–‡ä»¶è·¯å¾„: {json_file}")
                        
            except json.JSONDecodeError as e:
                self.logger.warning(f"JSONè§£æå¤±è´¥: {json_file} - {e}")
            except Exception as e:
                self.logger.warning(f"å¤„ç†æ–‡ä»¶æ—¶å‡ºé”™: {json_file} - {e}")
        
        self.logger.info(f"æ‰«æå®Œæˆï¼Œæ‰¾åˆ° {failed_count} ä¸ªå¤±è´¥è®°å½•")
        return failed_records
    
    def filter_by_error_codes(self, failed_records: List[Dict], error_codes: List[int]) -> List[Dict]:
        """
        æŒ‰é”™è¯¯ä»£ç ç­›é€‰å¤±è´¥è®°å½•
        
        Args:
            failed_records: å¤±è´¥è®°å½•åˆ—è¡¨
            error_codes: è¦é‡è¯•çš„é”™è¯¯ä»£ç åˆ—è¡¨
            
        Returns:
            ç­›é€‰åçš„å¤±è´¥è®°å½•åˆ—è¡¨
        """
        if not error_codes:
            return failed_records
        
        filtered = [record for record in failed_records 
                   if record.get('error_code') in error_codes]
        
        self.logger.info(f"æŒ‰é”™è¯¯ä»£ç ç­›é€‰: {len(failed_records)} -> {len(filtered)} æ¡è®°å½•")
        self.logger.info(f"ç›®æ ‡é”™è¯¯ä»£ç : {error_codes}")
        
        return filtered
    
    def generate_retry_statistics(self, failed_records: List[Dict]) -> Dict[str, Any]:
        """
        ç”Ÿæˆé‡è¯•ç»Ÿè®¡ä¿¡æ¯
        
        Args:
            failed_records: å¤±è´¥è®°å½•åˆ—è¡¨
            
        Returns:
            ç»Ÿè®¡ä¿¡æ¯å­—å…¸
        """
        stats = {
            'total_failed': len(failed_records),
            'by_error_code': {},
            'by_parent_type': {},
            'by_sub_type': {},
            'retry_attempts': {}
        }
        
        for record in failed_records:
            # æŒ‰é”™è¯¯ä»£ç ç»Ÿè®¡
            error_code = record.get('error_code', 'unknown')
            stats['by_error_code'][error_code] = stats['by_error_code'].get(error_code, 0) + 1
            
            # æŒ‰çˆ¶ç±»å‹ç»Ÿè®¡
            parent_type = record.get('parent_type', 'unknown')
            stats['by_parent_type'][parent_type] = stats['by_parent_type'].get(parent_type, 0) + 1
            
            # æŒ‰å­ç±»å‹ç»Ÿè®¡
            sub_type = record.get('sub_type', 'unknown')
            stats['by_sub_type'][sub_type] = stats['by_sub_type'].get(sub_type, 0) + 1
            
            # æŒ‰é‡è¯•æ¬¡æ•°ç»Ÿè®¡
            retry_count = record.get('retry_attempt', 0)
            stats['retry_attempts'][retry_count] = stats['retry_attempts'].get(retry_count, 0) + 1
        
        return stats
    
    def print_statistics(self, stats: Dict[str, Any]):
        """æ‰“å°ç»Ÿè®¡ä¿¡æ¯"""
        self.logger.info("\n" + "="*60)
        self.logger.info("å¤±è´¥è®°å½•ç»Ÿè®¡ä¿¡æ¯")
        self.logger.info("="*60)
        
        self.logger.info(f"å¤±è´¥è®°å½•æ€»æ•°: {stats['total_failed']}")
        
        self.logger.info("\næŒ‰é”™è¯¯ä»£ç åˆ†å¸ƒ:")
        for error_code, count in sorted(stats['by_error_code'].items()):
            error_name = self.get_error_name(error_code)
            self.logger.info(f"  {error_code} ({error_name}): {count} æ¡")
        
        self.logger.info("\næŒ‰çˆ¶ç±»å‹åˆ†å¸ƒ:")
        for parent_type, count in sorted(stats['by_parent_type'].items()):
            self.logger.info(f"  {parent_type}: {count} æ¡")
        
        self.logger.info("\næŒ‰é‡è¯•æ¬¡æ•°åˆ†å¸ƒ:")
        for retry_count, count in sorted(stats['retry_attempts'].items()):
            self.logger.info(f"  é‡è¯• {retry_count} æ¬¡: {count} æ¡")
        
        self.logger.info("="*60)
    
    def print_retry_details(self, failed_records: List[Dict], show_limit: int = 20):
        """
        æ‰“å°è¯¦ç»†çš„é‡è¯•è®°å½•ä¿¡æ¯
        
        Args:
            failed_records: å¤±è´¥è®°å½•åˆ—è¡¨
            show_limit: æ˜¾ç¤ºè®°å½•æ•°é‡é™åˆ¶ï¼Œé¿å…è¾“å‡ºè¿‡å¤š
        """
        self.logger.info("\n" + "="*80)
        self.logger.info("å°†è¦é‡è¯•çš„è®°å½•è¯¦æƒ…")
        self.logger.info("="*80)
        
        if not failed_records:
            self.logger.info("æ²¡æœ‰è®°å½•éœ€è¦é‡è¯•")
            return
        
        # æŒ‰é”™è¯¯ä»£ç åˆ†ç»„æ˜¾ç¤º
        error_groups = {}
        for record in failed_records:
            error_code = record.get('error_code', 'unknown')
            if error_code not in error_groups:
                error_groups[error_code] = []
            error_groups[error_code].append(record)
        
        total_shown = 0
        for error_code, records in sorted(error_groups.items()):
            error_name = self.get_error_name(error_code)
            self.logger.info(f"\né”™è¯¯ä»£ç  {error_code} ({error_name}) - {len(records)} æ¡è®°å½•:")
            
            for i, record in enumerate(records[:min(show_limit - total_shown, len(records))]):
                place_id = record['place_id']
                parent_type = record['parent_type']
                sub_type = record['sub_type']
                retry_count = record.get('retry_attempt', 0)
                scraped_at = record.get('scraped_at', 'Unknown')
                
                # å°è¯•æå–å•†æˆ·åç§°ï¼ˆå¦‚æœæœ‰çš„è¯ï¼‰
                business_name = self.extract_business_name_from_path(record['file_path'])
                name_display = f" ({business_name})" if business_name else ""
                
                self.logger.info(f"  {i+1:2d}. {place_id}{name_display}")
                self.logger.info(f"      ç±»å‹: {parent_type}/{sub_type}")
                self.logger.info(f"      é‡è¯•æ¬¡æ•°: {retry_count}, ä¸Šæ¬¡æŠ“å–: {scraped_at}")
                
                total_shown += 1
                if total_shown >= show_limit:
                    break
            
            if total_shown >= show_limit:
                remaining = len(failed_records) - total_shown
                if remaining > 0:
                    self.logger.info(f"\n  ... è¿˜æœ‰ {remaining} æ¡è®°å½•æœªæ˜¾ç¤º")
                break
        
        self.logger.info("\n" + "="*80)
        self.logger.info("æ–‡ä»¶å¤„ç†è¯´æ˜:")
        self.logger.info("â€¢ åŸå¤±è´¥æ–‡ä»¶å°†å¤‡ä»½åˆ° backup/retry_æ—¶é—´æˆ³/ ç›®å½•")
        self.logger.info("â€¢ backupç›®å½•ä¸­ä¿æŒä¸åŸoutputç›¸åŒçš„ç›®å½•ç»“æ„")
        self.logger.info("â€¢ é‡è¯•æˆåŠŸçš„ç»“æœå°†è¦†ç›–åŸæ–‡ä»¶ä½ç½®")
        self.logger.info("â€¢ é‡è¯•å¤±è´¥çš„è®°å½•å°†æ›´æ–°é”™è¯¯ä¿¡æ¯å’Œé‡è¯•æ¬¡æ•°")
        self.logger.info("="*80)
    
    def extract_business_name_from_path(self, file_path: str) -> Optional[str]:
        """
        ä»æ–‡ä»¶è·¯å¾„ä¸­æå–å•†æˆ·åç§°
        
        Args:
            file_path: æ–‡ä»¶è·¯å¾„
            
        Returns:
            å•†æˆ·åç§°ï¼ˆå¦‚æœèƒ½æå–åˆ°ï¼‰
        """
        try:
            file_name = Path(file_path).stem  # è·å–ä¸å«æ‰©å±•åçš„æ–‡ä»¶å
            # æ–‡ä»¶åæ ¼å¼é€šå¸¸æ˜¯ place_id_business_name.json
            if '_' in file_name:
                parts = file_name.split('_', 1)  # åªåˆ†å‰²ç¬¬ä¸€ä¸ªä¸‹åˆ’çº¿
                if len(parts) > 1:
                    return parts[1].replace('_', ' ')  # å°†ä¸‹åˆ’çº¿æ›¿æ¢å›ç©ºæ ¼
        except:
            pass
        return None
    
    def confirm_retry_operation(self, failed_records: List[Dict], show_details: bool = True) -> bool:
        """
        ç¡®è®¤é‡è¯•æ“ä½œ
        
        Args:
            failed_records: å¤±è´¥è®°å½•åˆ—è¡¨
            show_details: æ˜¯å¦æ˜¾ç¤ºè¯¦ç»†ä¿¡æ¯
            
        Returns:
            ç”¨æˆ·æ˜¯å¦ç¡®è®¤ç»§ç»­
        """
        if show_details:
            self.print_retry_details(failed_records)
        
        print(f"\nå‡†å¤‡é‡è¯• {len(failed_records)} æ¡å¤±è´¥è®°å½•")
        print("æ³¨æ„ï¼šè¿™ä¸ªæ“ä½œå°†ï¼š")
        print("â€¢ å°†å½“å‰å¤±è´¥æ–‡ä»¶å¤‡ä»½åˆ° backup/retry_æ—¶é—´æˆ³/ ç›®å½•")
        print("â€¢ é‡æ–°æŠ“å–è¿™äº›é¡µé¢çš„æ•°æ®")
        print("â€¢ ç”¨æ–°ç»“æœè¦†ç›–åŸæ–‡ä»¶ï¼ˆå¦‚æœé‡è¯•æˆåŠŸï¼‰")
        print("â€¢ æ›´æ–°é”™è¯¯ä¿¡æ¯ï¼ˆå¦‚æœé‡è¯•ä»ç„¶å¤±è´¥ï¼‰")
        
        # ğŸ”¥ æ–°å¢ï¼šæ˜¾ç¤ºå°†è¦ä½¿ç”¨çš„é…ç½®
        print(f"\nä½¿ç”¨çš„é…ç½®å‚æ•°:")
        print(f"â€¢ å¹¶å‘çº¿ç¨‹æ•°: {self.config.get('max_workers', 3)}")
        print(f"â€¢ å•é¡µè¶…æ—¶æ—¶é—´: {self.config.get('timeout', 300)} ç§’")
        print(f"â€¢ å•é¡µé‡è¯•æ¬¡æ•°: {self.config.get('max_retries', 3)}")
        print(f"â€¢ è¯¦ç»†æ—¥å¿—: {'å¼€å¯' if self.config.get('verbose_logging', False) else 'å…³é—­'}")
        
        while True:
            response = input(f"\nç¡®è®¤ç»§ç»­é‡è¯•æ“ä½œï¼Ÿ[y/N]: ").strip().lower()
            if response in ['y', 'yes', 'æ˜¯', 'ç¡®è®¤']:
                return True
            elif response in ['n', 'no', 'å¦', 'å–æ¶ˆ', '']:
                return False
            else:
                print("è¯·è¾“å…¥ y(æ˜¯) æˆ– n(å¦)")
    
    def get_error_name(self, error_code) -> str:
        """è·å–é”™è¯¯ä»£ç å¯¹åº”çš„åç§°"""
        error_names = {
            1001: "æµè§ˆå™¨åˆå§‹åŒ–å¤±è´¥",
            1002: "é¡µé¢åŠ è½½å¤±è´¥/è¶…æ—¶",
            1003: "å•†æˆ·ä¿¡æ¯æå–å¤±è´¥",
            1004: "è¯„è®ºæŒ‰é’®æœªæ‰¾åˆ°",
            1005: "è¯„è®ºæ»šåŠ¨å¤±è´¥",
            1006: "è¯„è®ºæå–å¤±è´¥",
            1007: "åæ ‡æå–å¤±è´¥",
            1008: "CSVä¿å­˜å¤±è´¥",
            1009: "ç½‘ç»œè¶…æ—¶",
            1010: "å…ƒç´ æœªæ‰¾åˆ°",
            1999: "æœªé¢„æœŸé”™è¯¯"
        }
        return error_names.get(error_code, "æœªçŸ¥é”™è¯¯")
    
    def fix_progress_file(self, failed_records: List[Dict]):
        """
        ä¿®å¤è¿›åº¦æ–‡ä»¶ä¸­å¤±è´¥è®°å½•çš„çŠ¶æ€
        
        ç¡®ä¿å¤±è´¥çš„place_idåœ¨progress.jsonä¸­è¢«æ­£ç¡®æ ‡è®°ä¸ºå¤±è´¥çŠ¶æ€
        
        Args:
            failed_records: å¤±è´¥è®°å½•åˆ—è¡¨
        """
        if not failed_records:
            return
            
        # è·å–æ‰€æœ‰å¤±è´¥çš„place_id
        failed_place_ids = [record['place_id'] for record in failed_records]
        
        self.logger.info(f"æ­£åœ¨ä¿®å¤è¿›åº¦æ–‡ä»¶ä¸­ {len(failed_place_ids)} ä¸ªå¤±è´¥è®°å½•çš„çŠ¶æ€...")
        
        # åŠ è½½å½“å‰è¿›åº¦
        progress = self.batch_processor.load_progress()
        
        # ç¡®ä¿failedåˆ—è¡¨å­˜åœ¨
        if 'failed' not in progress:
            progress['failed'] = []
        if 'successful' not in progress:
            progress['successful'] = []
        if 'skipped' not in progress:
            progress['skipped'] = []
        
        # å°†å¤±è´¥çš„place_idä»successfulå’Œskippedä¸­ç§»é™¤ï¼Œå¹¶æ·»åŠ åˆ°failedä¸­
        successful_set = set(progress['successful'])
        skipped_set = set(progress['skipped'])
        failed_set = set(progress['failed'])
        
        moved_count = 0
        for place_id in failed_place_ids:
            # ä»æˆåŠŸåˆ—è¡¨ä¸­ç§»é™¤ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
            if place_id in successful_set:
                successful_set.remove(place_id)
                moved_count += 1
                
            # ä»è·³è¿‡åˆ—è¡¨ä¸­ç§»é™¤ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
            if place_id in skipped_set:
                skipped_set.remove(place_id)
                moved_count += 1
                
            # æ·»åŠ åˆ°å¤±è´¥åˆ—è¡¨ä¸­
            failed_set.add(place_id)
        
        # æ›´æ–°è¿›åº¦å­—å…¸
        progress['successful'] = list(successful_set)
        progress['skipped'] = list(skipped_set)
        progress['failed'] = list(failed_set)
        
        # ä¿å­˜æ›´æ–°åçš„è¿›åº¦
        self.batch_processor.save_progress(progress)
        
        self.logger.info(f"å·²ä¿®å¤ {moved_count} ä¸ªè®°å½•çš„çŠ¶æ€ï¼Œ{len(failed_set)} ä¸ªè®°å½•ç°åœ¨æ ‡è®°ä¸ºå¤±è´¥")
        
        # éªŒè¯ä¿®å¤ç»“æœ
        updated_progress = self.batch_processor.load_progress()
        self.logger.info(f"ä¿®å¤åè¿›åº¦ç»Ÿè®¡: æˆåŠŸ {len(updated_progress.get('successful', []))}, "
                        f"å¤±è´¥ {len(updated_progress.get('failed', []))}, "
                        f"è·³è¿‡ {len(updated_progress.get('skipped', []))}")
    
    def convert_to_input_format(self, failed_records: List[Dict]) -> List[Dict]:
        """
        å°†å¤±è´¥è®°å½•è½¬æ¢ä¸ºè¾“å…¥æ ¼å¼
        
        Args:
            failed_records: å¤±è´¥è®°å½•åˆ—è¡¨
            
        Returns:
            è½¬æ¢åçš„è¾“å…¥æ ¼å¼åˆ—è¡¨
        """
        input_format = []
        
        for record in failed_records:
            input_record = {
                'place_id': record['place_id'],
                'Maps_url': record['Maps_url'],
                'parent_type': record['parent_type'],
                'sub_type': record['sub_type'],
                'grid_id': record.get('grid_id', '')
            }
            input_format.append(input_record)
        
        return input_format
    
    def backup_failed_files(self, failed_records: List[Dict], backup_suffix: Optional[str] = None):
        """
        å¤‡ä»½å¤±è´¥çš„æ–‡ä»¶åˆ°backupç›®å½•
        
        Args:
            failed_records: å¤±è´¥è®°å½•åˆ—è¡¨
            backup_suffix: å¤‡ä»½åç¼€ï¼Œé»˜è®¤ä½¿ç”¨æ—¶é—´æˆ³
        """
        if backup_suffix is None:
            backup_suffix = datetime.now().strftime("%Y%m%d_%H%M%S")
        
        # åˆ›å»ºbackupæ ¹ç›®å½•ï¼ˆä¸batch_outputå¹³è¡Œï¼‰
        backup_root = self.output_dir.parent / "backup" / f"retry_{backup_suffix}"
        backup_root.mkdir(parents=True, exist_ok=True)
        
        self.logger.info(f"æ­£åœ¨å¤‡ä»½ {len(failed_records)} ä¸ªå¤±è´¥æ–‡ä»¶åˆ°: {backup_root}")
        
        backup_count = 0
        for record in failed_records:
            try:
                original_file = Path(record['file_path'])
                if original_file.exists():
                    # è®¡ç®—ç›¸å¯¹äºoutput_dirçš„è·¯å¾„
                    relative_path = original_file.relative_to(self.output_dir)
                    
                    # åœ¨backupç›®å½•ä¸­åˆ›å»ºç›¸åŒçš„ç›®å½•ç»“æ„
                    backup_file = backup_root / relative_path
                    backup_file.parent.mkdir(parents=True, exist_ok=True)
                    
                    # å¤åˆ¶æ–‡ä»¶åˆ°backupç›®å½•ï¼ˆä¿æŒåŸæ–‡ä»¶ä¸å˜ï¼‰
                    shutil.copy2(original_file, backup_file)
                    backup_count += 1
                    
                    self.logger.debug(f"å·²å¤‡ä»½: {relative_path}")
                    
            except Exception as e:
                self.logger.warning(f"å¤‡ä»½æ–‡ä»¶å¤±è´¥: {record['file_path']} - {e}")
        
        self.logger.info(f"å·²å¤‡ä»½ {backup_count} ä¸ªæ–‡ä»¶åˆ°: {backup_root}")
        self.logger.info(f"å¤‡ä»½ç›®å½•ç»“æ„ä¸åŸoutputç›®å½•ä¿æŒä¸€è‡´")
        
        return backup_root
    
    def retry_failed_scrapes(self, 
                           failed_records: List[Dict],
                           max_workers: int = 3,
                           max_places: Optional[int] = None,
                           backup_files: bool = True,
                           update_retry_count: bool = True) -> Optional[Dict[str, Any]]:
        """
        é‡è¯•å¤±è´¥çš„æŠ“å–
        
        Args:
            failed_records: å¤±è´¥è®°å½•åˆ—è¡¨
            max_workers: æœ€å¤§å¹¶å‘æ•°
            max_places: æœ€å¤§é‡è¯•æ•°é‡
            backup_files: æ˜¯å¦å¤‡ä»½åŸå¤±è´¥æ–‡ä»¶
            update_retry_count: æ˜¯å¦æ›´æ–°é‡è¯•æ¬¡æ•°
            
        Returns:
            é‡è¯•ç»“æœç»Ÿè®¡ï¼Œå¦‚æœæ²¡æœ‰è®°å½•åˆ™è¿”å›None
        """
        if not failed_records:
            self.logger.warning("æ²¡æœ‰å¤±è´¥è®°å½•éœ€è¦é‡è¯•")
            return None
        
        # é™åˆ¶é‡è¯•æ•°é‡
        if max_places and max_places > 0:
            failed_records = failed_records[:max_places]
            self.logger.info(f"é™åˆ¶é‡è¯•æ•°é‡ä¸º: {len(failed_records)} æ¡")
        
        # ğŸ”¥ å…³é”®ä¿®å¤ï¼šå…ˆä¿®å¤è¿›åº¦æ–‡ä»¶ä¸­çš„å¤±è´¥è®°å½•çŠ¶æ€
        self.fix_progress_file(failed_records)
        
        # å¤‡ä»½åŸå¤±è´¥æ–‡ä»¶
        if backup_files:
            self.backup_failed_files(failed_records)
        
        # è½¬æ¢ä¸ºè¾“å…¥æ ¼å¼
        retry_input = self.convert_to_input_format(failed_records)
        
        self.logger.info(f"å¼€å§‹é‡è¯• {len(retry_input)} ä¸ªå¤±è´¥è®°å½•...")
        self.logger.info(f"ä½¿ç”¨é…ç½®: max_workers={max_workers}, timeout={self.config.get('timeout', 300)}s")
        
        # ğŸ”¥ ä¿®å¤ï¼šæ›´æ–°æ‰¹é‡å¤„ç†å™¨çš„é…ç½®
        self.batch_processor.config.update({
            'max_workers': max_workers,
            'timeout': self.config.get('timeout', 300),
            'max_retries': self.config.get('max_retries', 3)
        })
        
        try:
            result = self.batch_processor.process_batch(
                places=retry_input,
                max_workers=max_workers,  # ç¡®ä¿å‚æ•°ä¼ é€’
                retry_failed=True,  # å…³é”®ï¼šå¯ç”¨é‡è¯•æ¨¡å¼
                max_places=len(retry_input),
                resume=True,
                # ğŸ”¥ æ–°å¢ï¼šä¼ é€’é¢å¤–çš„é…ç½®å‚æ•°
                timeout=self.config.get('timeout', 300),
                max_retries=self.config.get('max_retries', 3),
                verbose=self.config.get('verbose_logging', False)
            )
            
            self.logger.info("é‡è¯•å¤„ç†å®Œæˆ")
            return result
            
        except Exception as e:
            self.logger.error(f"é‡è¯•å¤„ç†æ—¶å‡ºé”™: {e}")
            raise

def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(description="é‡è¯•å¤±è´¥çš„Google MapsæŠ“å–è®°å½•")
    
    parser.add_argument(
        "--output-dir",
        default="batch_output",
        help="è¾“å‡ºç›®å½•è·¯å¾„ (é»˜è®¤: batch_output)"
    )
    
    parser.add_argument(
        "--error-codes",
        type=int,
        nargs='+',
        help="åªé‡è¯•æŒ‡å®šé”™è¯¯ä»£ç çš„è®°å½• (ä¾‹å¦‚: --error-codes 1002 1009)"
    )
    
    parser.add_argument(
        "--max-retry",
        type=int,
        help="æœ€å¤§é‡è¯•è®°å½•æ•°é‡ (ç”¨äºæµ‹è¯•)"
    )
    
    parser.add_argument(
        "--max-workers",
        type=int,
        default=3,
        help="æœ€å¤§å¹¶å‘çº¿ç¨‹æ•° (é»˜è®¤: 3)"
    )
    
    parser.add_argument(
        "--no-backup",
        action="store_true",
        help="ä¸å¤‡ä»½åŸå¤±è´¥æ–‡ä»¶"
    )
    
    parser.add_argument(
        "--stats-only",
        action="store_true",
        help="åªæ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯ï¼Œä¸æ‰§è¡Œé‡è¯•"
    )
    
    parser.add_argument(
        "--verbose",
        action="store_true",
        help="å¯ç”¨è¯¦ç»†æ—¥å¿—"
    )
    
    parser.add_argument(
        "--test-mode",
        action="store_true",
        help="ä½¿ç”¨æµ‹è¯•æ¨¡å¼é…ç½®"
    )
    
    parser.add_argument(
        "--no-details",
        action="store_true",
        help="ä¸æ˜¾ç¤ºè¯¦ç»†çš„é‡è¯•è®°å½•ä¿¡æ¯"
    )
    
    parser.add_argument(
        "--show-limit",
        type=int,
        default=20,
        help="æ˜¾ç¤ºè¯¦ç»†ä¿¡æ¯æ—¶çš„è®°å½•æ•°é‡é™åˆ¶ (é»˜è®¤: 20)"
    )
    
    parser.add_argument(
        "--fix-progress-only",
        action="store_true",
        help="åªä¿®å¤è¿›åº¦æ–‡ä»¶ä¸­å¤±è´¥è®°å½•çš„çŠ¶æ€ï¼Œä¸æ‰§è¡Œé‡è¯•"
    )
    
    parser.add_argument(
        "--timeout",
        type=int,
        help="å•ä¸ªé¡µé¢çš„è¶…æ—¶æ—¶é—´ï¼ˆç§’ï¼‰ï¼Œé»˜è®¤ä½¿ç”¨é…ç½®æ–‡ä»¶ä¸­çš„å€¼"
    )
    
    parser.add_argument(
        "--max-retries",
        type=int,
        help="å•ä¸ªé¡µé¢çš„æœ€å¤§é‡è¯•æ¬¡æ•°ï¼Œé»˜è®¤ä½¿ç”¨é…ç½®æ–‡ä»¶ä¸­çš„å€¼"
    )
    
    args = parser.parse_args()
    
    # é€‰æ‹©é…ç½®
    config = TEST_CONFIG if args.test_mode else DEFAULT_CONFIG.copy()
    config['verbose_logging'] = args.verbose
    
    # ğŸ”¥ æ–°å¢ï¼šåº”ç”¨å‘½ä»¤è¡Œå‚æ•°è¦†ç›–é…ç½®
    if args.timeout:
        config['timeout'] = args.timeout
    if args.max_retries:
        config['max_retries'] = args.max_retries
    
    try:
        # åˆ›å»ºé‡è¯•å¤„ç†å™¨
        processor = FailedScrapeRetryProcessor(
            output_dir=args.output_dir,
            config=config
        )
        
        # æ‰«æå¤±è´¥è®°å½•
        failed_records = processor.scan_failed_files()
        
        if not failed_records:
            processor.logger.info("æ²¡æœ‰æ‰¾åˆ°å¤±è´¥è®°å½•")
            return
        
        # æŒ‰é”™è¯¯ä»£ç ç­›é€‰
        if args.error_codes:
            failed_records = processor.filter_by_error_codes(failed_records, args.error_codes)
            if not failed_records:
                processor.logger.info("æŒ‰é”™è¯¯ä»£ç ç­›é€‰åæ²¡æœ‰åŒ¹é…çš„å¤±è´¥è®°å½•")
                return
        
        # ç”Ÿæˆå’Œæ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯
        stats = processor.generate_retry_statistics(failed_records)
        processor.print_statistics(stats)
        
        # å¦‚æœåªä¿®å¤è¿›åº¦æ–‡ä»¶ï¼Œåˆ™æ‰§è¡Œä¿®å¤åé€€å‡º
        if args.fix_progress_only:
            processor.logger.info("åªä¿®å¤è¿›åº¦æ–‡ä»¶æ¨¡å¼")
            processor.fix_progress_file(failed_records)
            processor.logger.info("è¿›åº¦æ–‡ä»¶ä¿®å¤å®Œæˆï¼")
            return
        
        # å¦‚æœåªæ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯ï¼Œåˆ™é€€å‡º
        if args.stats_only:
            processor.logger.info("ä»…æ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯æ¨¡å¼ï¼Œä¸æ‰§è¡Œé‡è¯•")
            return
        
        # æ”¹è¿›çš„ç¡®è®¤æœºåˆ¶
        show_details = not args.no_details
        if args.test_mode or args.max_retry:
            # æµ‹è¯•æ¨¡å¼æˆ–é™åˆ¶æ•°é‡æ—¶ï¼Œè‡ªåŠ¨æ˜¾ç¤ºè¯¦æƒ…ä½†ä¸éœ€è¦ç¡®è®¤
            if show_details:
                processor.print_retry_details(failed_records, args.show_limit)
            processor.logger.info("æµ‹è¯•æ¨¡å¼æˆ–é™åˆ¶æ¨¡å¼ï¼Œè·³è¿‡ç”¨æˆ·ç¡®è®¤")
        else:
            # æ­£å¸¸æ¨¡å¼ï¼Œéœ€è¦ç”¨æˆ·ç¡®è®¤
            if not processor.confirm_retry_operation(failed_records, show_details):
                processor.logger.info("ç”¨æˆ·å–æ¶ˆé‡è¯•æ“ä½œ")
                return
        
        # æ‰§è¡Œé‡è¯•
        result = processor.retry_failed_scrapes(
            failed_records=failed_records,
            max_workers=args.max_workers,
            max_places=args.max_retry,
            backup_files=not args.no_backup
        )
        
        processor.logger.info("é‡è¯•æ“ä½œå®Œæˆï¼")
        
    except KeyboardInterrupt:
        print("\nç”¨æˆ·ä¸­æ–­æ“ä½œ")
        sys.exit(1)
    except Exception as e:
        print(f"é‡è¯•å¤„ç†å‡ºé”™: {e}")
        if args.verbose:
            import traceback
            traceback.print_exc()
        sys.exit(1)

if __name__ == "__main__":
    main() 